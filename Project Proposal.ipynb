{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recycling centers have trouble with materials that get passed on to them that are uncategorized. It is very inconvenient to manually sort the items so that they can be properly recycled according to the type of material they consist of. The goal of the project is to develop a neural network that can classify at least two different categories of recyclable materials. Some of the possible recyclable categories are: plastic bottles, colored glass bottles, carton jugs, cans, paper, and cardboard. The categories chosen are some of the most common recycled items. There are many other recyclable materials that the project could expand on, but it would be more difficult for the network to distinguish between all of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team will be developing a convolutional neural network, since the network will be working with many images that need to be categorized based on a distinct set of features for each category and convolutional neural networks are optimal for detecting features for each category of images. In order to develop the neural net, a significant number of images will be gathered from which will be used to train the network to identify which category a new recyclable item would belong to. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data will consist of color images that have the materials of the categories we will train the network on. The background of the images could be either white or varied, depending on the feasibility of training the network to recognize the materials from different backgrounds. Since the project will not focus on categorizing anything other than the materials listed, the data will only consist of images that contain the materials that the network will be trained to categorize. Initial testing and training will be conducted on just a small number of categories of materials with the number of categories increasing as prior versions of the network are improved. This data will be retrieved by implementing and then using a web scraping tool to pull relevant images from search engines, using the search engine’s search functionality to help ensure images gathered will be suitable to our needs. ImageNet is another potential source for various images that might be necessary. Once our data is gathered, members of our development team will sort through and identify which images we’ve gathered are suitable for use in the training and testing set. TensorFlow and Keras will be used for the coding of the network. The network might be trained with a part of the dataset and tested with another part of the dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success of the network will be achieved if the network is able to properly categorize eighty percent of the testing data for at least two categories. If the network is able to recognize paper, even if the paper has different inks, colors, letters, or images on it, and distinguish clear glass bottles versus clear plastic bottles, it would be considered a success since those would be difficult things for a neural network to distinguish between. At the minimum, the network should be able to distinguish two materials that look completely different from each other, such as cardboard and cans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
